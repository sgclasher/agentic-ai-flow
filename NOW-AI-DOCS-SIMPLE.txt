# ServiceNow Agentic AI: Comprehensive Guide

## Part 1: Foundations, Use Cases, and Agent Configuration

### 1. Introduction to ServiceNow Agentic AI

**What are Now Assist AI Agents?**

* Now Assist AI Agents are intelligent entities within ServiceNow that utilize Large Language Models (LLMs) to perform tasks ranging from simple automation to complex problem-solving[cite: 11].
* They operate based on a set of instructions and tools to achieve specific goals, such as resolving incidents or cases[cite: 12, 48].
* Their primary aim is to reduce the workload of human agents and enhance productivity[cite: 13, 41].
* AI Agents are designed to leverage your ServiceNow data, workflows, and integrations natively and securely[cite: 50].
* They can dynamically adjust their actions based on progress and changing conditions to stay focused on their objectives[cite: 51].

**Key Terminology** [cite: 46]

* **Agentic System:** A type of software or AI that perceives its environment, makes decisions, and takes actions to achieve goals with minimal human intervention. It can learn, adapt, and operate independently[cite: 46, 47]. ServiceNow's agentic framework is an example of this.
* **AI Agent:** Within the Now Platform, an AI agent consists of LLM instructions combined with tools (like skills, scripts, flows) to perform specific tasks[cite: 48, 3020].
* **Use Case:** In the ServiceNow agentic system, a use case defines an objective and comprises LLM instructions along with one or more AI agents needed to execute it[cite: 49].
* **Skill:** A generative AI capability assigned to an AI agent to perform specific tasks (e.g., summarization, classification, content generation)[cite: 3020]. Skills are a type of tool agents can use.
* **Tool:** Capabilities leveraged by AI Agents, including skills, scripts, flows, retrievers, etc.[cite: 48, 3020, 3028].
* **Orchestrator:** A coordinating entity within the agentic framework that manages collaboration between multiple agents, routing requests and facilitating complex task completion[cite: 68]. It can also interact with agents to get missing context or handle failures iteratively[cite: 69, 70].

**Capabilities & Benefits** [cite: 52]

* Dynamically plan incident/case resolution[cite: 52].
* Collaborate with other AI agents for subtasks[cite: 53].
* Incorporate human feedback when needed[cite: 53, 55].
* Handle knowledge-intensive tasks[cite: 54].
* Find solutions using multiple knowledge sources or similar incidents[cite: 54].
* Define specific flows to avoid unnecessary iterations[cite: 55].

**Important Considerations:**

* **AI Limitations:** AI/ML models generate predictions based on data patterns and may not always be accurate, complete, or appropriate[cite: 29, 32, 3787, 3788]. It's crucial to test, evaluate, and employ human oversight, especially for consequential use cases[cite: 34, 35, 3790, 3791].
* **Data Processing & Privacy:** Data may be transferred to centralized ServiceNow environments (potentially in different regions) or third-party providers like Microsoft Azure[cite: 37, 3793]. Data handling adheres to ServiceNow policies[cite: 38, 3794].
* **Data Collection for Improvement:** ServiceNow collects inputs/outputs to improve its technologies. Customers can opt out[cite: 39, 40, 3795, 3796].
* **Availability:** Some Now Assist features may have regional or environmental restrictions (e.g., FedRAMP)[cite: 23, 26, 3779, 3782]. Check ServiceNow KB articles for details[cite: 24, 27, 3780, 3783].

### 2. Identifying and Implementing AI Agent Use Cases

Identifying the right use cases is critical for success. Follow a structured approach:

**Step 1: Analyze (Identify Opportunities)** [cite: 2214]

* Think of AI Agents as virtual workers capable of handling tasks currently done by humans[cite: 2214].
* Focus on areas with potential for significant automation, especially high-volume transactional processes (cases, incidents)[cite: 2215].
* Consider under-resourced domains like knowledge management, problem management, or continuous improvement[cite: 2216].
* **Demand-Driven Approach:** [cite: 2217]
    * **Ticket/Feedback Analysis:** Analyze inquiries, incidents, and HR cases to find recurring themes or issues suitable for AI[cite: 2217].
    * **Identify Repetitive Tasks:** Look for time-consuming, repetitive tasks frequently reported as blockers or resulting in new tickets[cite: 2218].
    * **AI-Powered Analysis:** Use AI itself to categorize inquiries and identify emerging issues or potential use cases[cite: 2219, 2220].

**Step 2: Assess (Qualify Use Cases)** [cite: 2225]

* Determine if an AI Agent is the *right* solution. Not all automation needs an agentic approach[cite: 2223]. Simple tasks might be better suited for standard Now Assist skills triggered manually[cite: 2224].
* Consider AI Agents when: [cite: 2226]
    * **Contextual Understanding is Needed:** The process requires interpreting nuanced language, ambiguity, or diverse data formats beyond rule-based automation[cite: 2226].
    * **Frequent Variations/Updates:** Workflows or source data (policies, KBs) change often, making static automation difficult to maintain. AI Agents adapt more easily[cite: 2227, 2228].
    * **Scaling Expertise is Valuable:** You need to replicate and scale subject matter expertise currently held by a few individuals[cite: 2228].
    * **Complex Decision-Making:** The task involves multi-step reasoning, evaluating options, or synthesizing information from various sources[cite: 2228].
    * **Human-in-the-Loop is Beneficial:** Tasks require occasional human judgment, approval, or intervention within an automated process[cite: 2228].

**Step 3: Prioritize**

* (Details likely in subsequent sections of `servicenow-ai-agents-plan.txt` - will be covered later if present) Evaluate qualified use cases based on factors like business value, feasibility, complexity, data availability, and strategic alignment.

**Step 4: Implement**

* (Details likely in subsequent sections of `servicenow-ai-agents-plan.txt`, `Now Assist Skill Kit â€“ Implementation Guide.txt`, `yokohama_enable_ai_now_assist_ai_agents...txt` - will be covered later) Design, build, test, and deploy the AI Agent solution using tools like AI Agent Studio and Now Assist Skill Kit.

### 3. Configuring the Agentic AI Experience

**AI Agent Studio** [cite: 20, 62]

* The central hub for configuring the agentic AI experience[cite: 20].
* Provides guidance ("Steps to success") for implementing AI agents[cite: 62, 66].
* Used to create custom AI agents, potentially using advanced multi-agent reasoning frameworks[cite: 21].
* Allows creation and management of use cases, including defining instructions and triggers[cite: 22].
* Enables cloning and modification of existing use cases (base system use cases are read-only)[cite: 56, 57].
* Provides an interface (Agent Studio Chat, Now Assist panel) to interact with agents and view outputs, including citations from tools like knowledge search[cite: 76].

**AI Agents Orchestrator** [cite: 67]

* Manages how teams of AI agents collaborate[cite: 67, 68].
* Routes requests between agents to accomplish complex tasks[cite: 68].
* Can retrieve missing context or information by interacting with involved agents[cite: 69].
* Handles situations where an agent gets stuck, enabling iterative problem-solving[cite: 70].
* Helps manage, govern, and track the value of AI agents and use cases across the enterprise (via AI Agent Control Tower functionality)[cite: 67].

# ServiceNow Agentic AI: Comprehensive Guide

## Part 2: Now Assist Skill Kit & Skill Design

### 4. Now Assist Skill Kit (NASK) Overview

* The Now Assist Skill Kit is the ServiceNow toolkit for creating and publishing custom generative AI capabilities (Skills) for Now Assist and, by extension, AI Agents.
* It allows developers to build tailored Skills beyond the pre-built ones offered by ServiceNow.
* **Key Functionality:**
    * Define triggers for when a skill should activate.
    * Implement pre-processing logic to prepare data for the LLM.
    * Craft detailed prompts to instruct the LLM.
    * Manage context provided to the LLM using various tools.
    * Implement post-processing logic to format or act upon the LLM's output.
    * Test and publish skills for use within the platform.
* **Important Note:** NASK enables creating *new* workflow-related skills within the scope of your Now Assist licenses. You should leverage licensed, pre-built Now Assist skills (like Incident Summarization) where available and avoid creating duplicative versions of licensable skills. Custom skills *can* be built using NASK to operate on custom tables included in your licenses.

### 5. Skill Design and Development Principles

Designing effective skills involves several key stages:

**5.1 Triggering Skills**

* Skills need defined triggers to initiate their execution within a workflow or AI Agent's plan.
* **Common Trigger Mechanisms:**
    * **UI Actions:** Buttons or links clicked by a user.
    * **Flow Designer Actions:** Skills can be embedded as actions within automated workflows.
    * **Agent Workspace Events:** Actions taken within the Agent Workspace interface.
    * **AI Agent Orchestration:** An AI Agent, guided by its instructions and the Orchestrator, can decide to invoke a specific skill as part of its task execution plan.
* The trigger mechanism often provides the initial context or input data for the skill (e.g., the current incident record).

**5.2 Pre-Processing**

* This stage prepares the input data *before* it's sent to the LLM along with the prompt.
* **Purpose:**
    * **Format Data:** Structure data in a way the LLM can easily understand.
    * **Filter Information:** Remove irrelevant data to keep the context concise and focused.
    * **Extract Key Details:** Pull specific fields or information needed for the prompt.
    * **Anonymize/Mask Data:** Protect sensitive information (PII) before sending it to the LLM (See Responsible AI section later).
* **Implementation:** Often done using ServiceNow platform capabilities like Scripts (JavaScript) or Flow Designer logic.

**5.3 Prompt Engineering**

* This is the art and science of crafting effective instructions (prompts) for the LLM to achieve the desired outcome. It's crucial for guiding the AI Agent's behavior when using a skill.
* **Key Elements:**
    * **Clear Instructions:** Explicitly state the task the LLM should perform (e.g., "Summarize the following incident description," "Classify this user request," "Generate a draft resolution plan").
    * **Context:** Provide necessary background information (often handled via Context Management, see below).
    * **Role Setting:** Define the persona the LLM should adopt (e.g., "You are a helpful IT support agent").
    * **Format Specification:** Define the desired output format (e.g., "Provide the summary as bullet points," "Output should be JSON").
    * **Constraints:** Set boundaries or rules (e.g., "Keep the summary under 100 words," "Only use information from the provided knowledge article").
    * **Few-Shot Examples (Optional):** Provide examples of desired input/output pairs to guide the LLM's response style and format.
* **Best Practices:**
    * **Be Specific:** Avoid ambiguity.
    * **Iterate:** Prompt engineering is often an iterative process. Test, refine, and test again.
    * **Keep it Concise:** While providing necessary detail, avoid overly long or complex prompts that might confuse the LLM.
    * **Use Placeholders:** Use variables (e.g., `${incident.description}`) within the prompt template to dynamically insert data during pre-processing or context management.
* **ServiceNow Implementation:** Prompts are configured within the Skill definition in NASK, often using Prompt Templates.

**5.4 Context Management**

* This involves providing the *right* information to the LLM *at the right time* alongside the prompt instructions. This is critical for grounding the LLM's responses in relevant, up-to-date information. AI Agents rely heavily on effective context management.
* **Methods & Tools:**
    * **Record Context:** Passing data directly from the current ServiceNow record (e.g., incident fields, work notes).
    * **Scripted Context:** Using server-side scripts (JavaScript) to fetch, process, and format data from various sources within ServiceNow (e.g., related records, user profiles).
    * **Flow Context:** Leveraging Flow Designer actions to gather and structure context.
    * **Retrievers (Key for RAG):**
        * **Purpose:** Tools that dynamically search for and retrieve relevant information to inject into the prompt context. This is the core of Retrieval-Augmented Generation (RAG).
        * **Types:**
            * **Knowledge Base Search:** Retrieves relevant KB articles based on the input query or record context. Uses semantic search for better relevance.
            * **Record Search:** Finds similar records (e.g., past incidents, problems) based on context.
            * **Dataset Retriever:** Queries datasets curated using the Now Assist Data Kit (covered later).
        * **Benefit:** Allows the LLM to generate responses based on specific, current knowledge rather than just its general training data. Enhances accuracy and relevance.
    * **Short-Term Memory:** AI Agents maintain a temporary memory (often part of the Orchestrator's function) to recall recent interactions or intermediate results within a single task execution.
* **Implementation:** Configured within the Skill definition in NASK, associating specific context tools (like retrievers or scripts) with the skill.

**5.5 Post-Processing**

* This stage handles the LLM's generated output *after* it's received.
* **Purpose:**
    * **Format Output:** Convert the LLM's raw text into a specific format (e.g., JSON, update record fields).
    * **Extract Information:** Pull specific pieces of data from the LLM's response.
    * **Validate Output:** Check the response for adherence to requirements or potential issues.
    * **Trigger Actions:** Use the output to update records, initiate other workflows, or present information to the user.
    * **Parse Structured Output:** If the LLM was prompted to generate structured data (like JSON), parse it for further use.
* **Implementation:** Similar to pre-processing, often uses Scripts or Flow Designer logic configured within the Skill definition.

**(An end-to-end example implementation pulling these concepts together is mentioned in the `Now Assist Skill Kit â€“ Implementation Guide.txt` and can be elaborated on if needed, though it might make this section very long.)**

# ServiceNow Agentic AI: Comprehensive Guide

## Part 3: Data Kit, LLM Selection, and Best Practices

### 6. Now Assist Data Kit

* **Purpose:** Now Assist Data Kit allows you to create curated, reusable datasets from your ServiceNow data (e.g., specific incident types, knowledge articles, catalog items).
* **Functionality:**
    * Define datasets based on specific tables and filter conditions.
    * Publish datasets to a data catalog.
    * Make these curated datasets available for AI Skill development and testing.
* **How it Works with Skills/Agents:**
    * **Contextual Grounding:** Datasets created with the Data Kit can be queried by "Dataset Retriever" tools within a Skill's Context Management setup. This allows AI Agents to use highly specific, curated information from your instance for Retrieval-Augmented Generation (RAG).
    * **Skill Testing:** Use defined datasets to provide consistent test inputs when developing and evaluating custom skills.
* **Roles:** Requires specific roles (e.g., `sn_data_kit.admin` to create/publish, `sn_data_kit.analyst` for read/edit ground truth) to manage datasets.

### 7. Choosing an LLM

Selecting the appropriate LLM is vital for the performance, cost, and compliance of your AI Agents and Skills.

* **ServiceNow NowLLM:** ServiceNow offers its own domain-specific LLMs, trained on ServiceNow data and workflows, designed for enterprise use cases on the Now Platform. These are often the preferred choice for general platform tasks.
* **Third-Party LLMs (e.g., Azure OpenAI):** ServiceNow integrates with major third-party LLM providers. These might be considered for:
    * Specific tasks where a particular external model excels.
    * Use cases requiring capabilities not yet optimized in NowLLMs.
    * Compliance or regional requirements met by a specific provider.
* **Key Selection Criteria:**
    * **Task Appropriateness:** How well does the model perform the specific task(s) required by the Skill or Agent (e.g., summarization, classification, code generation, reasoning)?
    * **Performance:** Speed (latency) and accuracy of the model's responses.
    * **Cost:** Pricing models of different providers.
    * **Data Security & Privacy:** How the provider handles your data, compliance certifications (e.g., GDPR, HIPAA), and data residency options. ServiceNow emphasizes its trust and privacy standards for NowLLM and partner integrations.
    * **Scalability:** Can the model handle the expected volume of requests?
    * **Customization/Fine-tuning:** Options available for adapting the model (though often complex and less common for general use).
    * **Alignment with ServiceNow:** NowLLMs are inherently aligned with the platform's data structures and processes.
* **Recommendation:** Start with ServiceNow NowLLMs where possible due to their integration and domain specificity. Evaluate third-party models based on specific needs and the criteria above. The choice can often be configured per Skill or Agent use case.

### 8. Best Practices, Readiness, and Governance

Implementing agentic AI successfully requires careful planning and preparation across multiple areas.

**8.1 Data Readiness**

Generative AI, including AI Agents, heavily relies on high-quality, accessible data.

* **Methodology:** Treat data as a product. Define clear ownership, quality standards, and access controls.
* **Availability & Readiness:** Ensure the data required for your prioritized use cases exists and is accessible within ServiceNow.
* **Quality & Completeness:**
    * Assess data for accuracy, consistency, and completeness. Poor data leads to poor AI performance.
    * Implement data quality rules and cleansing processes.
* **Transformation:** Structure data appropriately for AI consumption (e.g., clear text fields vs. complex codes).
* **Processing Speed & Indexing:** Ensure data sources (especially for RAG) are indexed efficiently for fast retrieval (e.g., AI Search indexing for KBs).
* **Data Dictionary & Standardization:** Maintain clear definitions for data fields and ensure consistent use across the platform.
* **Use-Case Specific Structuring:** Tailor data representation for specific AI tasks.
* **Retrieval & Orchestration:** Design how Agents will access and use different data sources (records, KBs, datasets).
* **Structured vs. Unstructured Data:** Plan how Agents will utilize both (e.g., structured fields from incidents, unstructured text from work notes or emails).
* **PII Masking & Security:** Crucial for compliance. Implement robust mechanisms (like ServiceNow PII masking capabilities) to prevent sensitive data from being exposed to LLMs or in generated outputs where inappropriate. (See Responsible AI below).

**8.2 Responsible AI: Compliance & Security**

Build trust and ensure ethical deployment.

* **Compliance:**
    * Understand and adhere to relevant regulations (GDPR, CCPA, industry-specific rules).
    * Define clear policies for AI usage, data handling, and user consent.
    * Ensure auditability of AI Agent actions and decisions.
* **Security:**
    * Protect against unauthorized access to AI models and sensitive data.
    * Secure integrations with third-party LLMs.
    * Implement PII masking/anonymization rigorously, especially before sending data to LLMs. Define which fields contain PII.
    * Monitor for potential misuse or biased outputs.
* **Practical Guidance:**
    * **Human Oversight:** Implement human-in-the-loop checkpoints for critical decisions or outputs.
    * **Transparency:** Be clear about where and how AI Agents are being used. Provide visibility into how Agents make decisions (e.g., citing sources used in RAG).
    * **Fairness & Bias Mitigation:** Test for and mitigate potential biases in data and model outputs.
    * **Accountability:** Define who is responsible for the actions and outcomes of AI Agents.
    * **Now Assist Features:** Leverage built-in Now Assist safety features and ServiceNow's trust/privacy commitments.

**8.3 Organizational Change Management (OCM)**

Prepare your organization for the introduction of AI Agents.

* **Overview:** Address the people side of change to ensure adoption and value realization.
* **Preparing for Change:**
    * **Communicate Vision & Benefits:** Clearly articulate *why* AI Agents are being introduced and the expected value.
    * **Stakeholder Engagement:** Involve key stakeholders (users, managers, IT staff) early and often.
    * **Assess Impact:** Understand how AI Agents will change roles, processes, and required skills.
* **Managing Change:**
    * **Training & Education:** Provide training on how to interact with AI Agents and understand their capabilities/limitations.
    * **Support Structures:** Establish channels for users to ask questions and provide feedback.
    * **Pilot Programs:** Start with pilot groups to gather feedback and refine the solution before broad rollout.
* **Reinforcing Change:**
    * **Monitor Adoption & Value:** Track usage and measure the impact against defined KPIs.
    * **Celebrate Successes:** Share positive outcomes and user stories.
    * **Continuous Improvement:** Gather feedback and iteratively improve AI Agent performance and use cases.

**8.4 Platform Preparation & Prerequisites**

Ensure your ServiceNow instance is ready.

* **Prerequisites:** Verify necessary plugins are active (e.g., AI Agent Studio, Now Assist components, relevant workflow engines).
* **Review Features:** Understand the capabilities and limitations of the specific Now Assist and AI Agent features you plan to use.
* **Validate Compatibility:** Ensure compatibility with your instance version and other customizations.
* **Activate Now Assist:** Configure and activate necessary Now Assist features and LLM connections.

**8.5 Rollout Planning**

Deploy strategically.

* **Technical Deployment:** Plan the technical steps for activating agents, skills, and use cases in production.
* **Phased Approach:** Consider rolling out to specific user groups or for limited use cases initially.
* **Monitoring & Hypercare:** Plan for close monitoring immediately after go-live to quickly address any issues.
* **Rollback Plan:** Have a contingency plan if major issues arise.
* **Communication:** Clearly communicate rollout schedules and expectations to users.

**8.6 Measuring Value and Quality**

Track the impact and ensure ongoing performance.

* **Value Measurement:**
    * Define clear Key Performance Indicators (KPIs) aligned with the use case objectives (e.g., reduced resolution time, improved agent productivity, cost savings, enhanced employee/customer satisfaction).
    * Establish baseline metrics before deployment.
    * Implement mechanisms to track and report on KPIs post-deployment (e.g., Performance Analytics dashboards).
* **Quality Measurement:**
    * **Accuracy:** How often does the agent perform the task correctly? (e.g., correct classification, relevant summary).
    * **Relevance:** Is the information retrieved or generated by the agent pertinent to the task?
    * **Completeness:** Does the agent provide all necessary information or complete all required steps?
    * **User Feedback:** Collect qualitative feedback from users interacting with the agents.
    * **Failure Analysis:** Analyze instances where the agent failed or produced incorrect results to identify areas for improvement (prompt tuning, context refinement, data quality issues).
    * **Testing:** Implement rigorous testing strategies (unit, integration, user acceptance) before deployment and for ongoing regression testing.

# ServiceNow Agentic AI & Now Assist - Extracted Technical Details (Consolidated)

This document summarizes tables, fields, APIs, scripting objects, roles, properties, and concepts related to ServiceNow's Agentic AI framework and Now Assist capabilities, based on the provided documents.

**Note:** This list is compiled from documentation snippets and code examples. It may not be exhaustive, and exact schemas (field names, types, relationships) should always be verified within a ServiceNow instance, typically via the `sys_dictionary` table. Table names inferred from context are noted.

## Tables

* **Agentic AI Framework:**
    * `sn_aia_usecase`: Stores Use Case definitions.
    * `sn_aia_team`: Defines agent teams.
    * `sn_aia_team_member`: Maps agents to teams.
    * `sn_aia_agent` / `sn_aia_agent_config`: Agent definitions/configurations.
    * `sn_aia_tool`: Tool definitions.
    * `sn_aia_agent_tool_m2m`: Agent-Tool mapping.
    * `sn_aia_trigger_configuration`: Use Case triggers.
* **Natural Language Understanding (NLU):**
    * `Discovery Report [sn_nlu_discovery_report]`: NLU discovery clusters and intents[cite: 2743].
    * `Discovery Message [sn_nlu_discovery_message]`: Stores NLU discovery messages (Inferred name)[cite: 2744].
* **Predictive Intelligence (PI):**
    * `ml_predictor_results`: Stores PI results[cite: 2850].
    * `ml_predictor_results_task`: Stores PI task results[cite: 2850].
* **AI Assets API Related:**
    * `AI Dataset Asset [alm_ai_dataset_digital_asset]`: Table for AI Dataset Assets[cite: 2385].
    * `Asset [alm_asset]`: Generic asset table, used by AI Assets API[cite: 2381].
    * `Product Model [cmdb_model]`: Product model table, used by AI Assets API[cite: 2381].
    * `Configuration Item [cmdb_ci]`: Base CI table, used by AI Assets API[cite: 2381].
* **Platform / General:**
    * `sys_hub_flow`: Stores Flow Designer flows.
    * `sys_one_extend_capability`: Likely relates to Skill/Capability definitions (NASK).
    * `sys_one_extend_definition`: Likely related definitions for Capabilities (NASK).
    * `sn_one_extend_skill`: Likely relates to Skills (NASK).
    * `sn_gen_ai_config`: General GenAI configurations.
    * `Data Classification [data_classification]`: Stores data classifications[cite: 199, 200].
    * `Decision [sys_decision_question]`: Stores decision questions[cite: 396].
    * `Documents [ds_document]`: Stores documents (related to `sn_doc_services`)[cite: 1739].
    * `User [sys_user]`: Standard user table[cite: 3540].
    * `UI Page [sys_ui_page]`: Stores UI Page definitions[cite: 1325].
* **Document Intelligence (DocIntel):** Specific table names not explicitly listed, likely within `sn_docintel` scope.
* **Now Assist Data Kit:** Specific table names not explicitly listed, likely within `sn_dk` or `sn_data_kit` scope.
* **Now Assist Skill Kit:** Specific table names not explicitly listed, likely within `sn_nask` scope or related to `sys_one_extend_*` tables.

## Fields (Examples from Context/APIs)

* **Agentic AI Fields:**
    * `team` (on `sn_aia_usecase`): Links to `sn_aia_team`.
    * `usecase` (on `sn_aia_trigger_configuration`): Links to `sn_aia_usecase`.
* **Standard Fields:**
    * `sys_id` (on all tables): Unique record identifier.
    * `sys_scope` (on many tables): Application scope identifier.
    * `name` / `display_name` (common on configuration tables): Name/label.
    * `active` (common on configuration tables): Boolean status flag.
* **API Parameter/Response Examples:**
    * `.parent.sys_id` (on `data_classification` reference)[cite: 199].
    * `.parent.name` (on `data_classification` reference)[cite: 200].
    * `items.sys_object_source_info.source_name` (in CMDB API context)[cite: 1212].
    * `headers` (Object on request object)[cite: 1559].
    * `account.country`, `account.customer` (on `sys_user` via API)[cite: 3540, 3600].
    * `articles.fields.<field_name>.value` (in Knowledge API context)[cite: 4356].
    * `Resources.name.familyName`, `Resources.name.givenName` (in SCIM API context)[cite: 4444].
    * `cases.parent` (Sys_id of parent case)[cite: 4187].
    * `Utterance`, `Text to Summarize`, `Response`, `Provider`, `Action Status` (Flow action inputs/outputs)[cite: 1567, 1569, 1570, 1571, 1573, 1577, 1580, 1583, 1584].
* **Document Intelligence Concept Fields:** `field`, `field group`, `field value`, `recommendation`[cite: 3680, 3682, 3685, 3686, 3689, 3690].

## APIs / Scripting Objects / Methods

* **Server-Side (Scoped & Global):**
    * `GlideRecord`: Core database API (methods: `addQuery`, `query`, `getRowCount`, `getValue`, `getDisplayValue`, `getUniqueValue`, `isValidField`, `next`, etc.).
    * `GlideDateTime`: Date/time handling (`getDisplayValue`).
    * `gs` (GlideSystem): System methods (`gs.info`, `gs.warn`).
    * `GlideElement`: Field object API (`getJournalEntry`)[cite: 983].
    * `sn_ml.PredictabilityEstimateStore`: `getAllNames()`[cite: 1442].
    * `SimilaritySolution`: `getName()`[cite: 1617].
    * `SimilaritySolutionVersion`: `getProperties()`[cite: 1677].
    * `sn_doc_services.DocumentListService`: `createDocumentList()`[cite: 670].
    * `TableUtils`: `dropTableAndExtensions()`[cite: 1798].
    * `DecisionTableAPI`: `getAnswers()`[cite: 395].
    * `PolarisUI` (Scoped): Next Experience UI Page methods[cite: 1324].
    * `GlideUICompatibility` (Scoped): UI compatibility methods[cite: 4698].
    * `hr_ActivitySet` (Server): Example HRSD API[cite: 4698].
    * `NowGraphQLService()`: For multi-table GraphQL queries[cite: 4742].
* **Client-Side:**
    * `GlideNavigation`[cite: 4698].
    * `GlideUIScripts`[cite: 4698].
    * `GlideList` (Now Experience)[cite: 4698].
    * Ajax Scripts (Client/Server interaction)[cite: 5013].
    * Client Scripts (`onLoad`, `onChange`, `onSubmit`)[cite: 5006, 5015].
* **REST APIs (Examples):**
    * **Table API:** `/api/now/table/{tableName}` (Standard CRUDQ operations).
    * **Aggregate API:** `/api/now/stats/{tableName}` (Aggregations like COUNT, SUM, AVG)[cite: 4559].
    * **Attachment API:** `/api/now/attachment`.
    * **Import Set API:** `/api/now/import/{staging_table_name}` (Load data into import set tables)[cite: 4137].
    * **AI Assets API:** `/api/sn_ent/asset/ai_dataset/{sys_id}` (Requires `sn_ent` plugin)[cite: 2376, 2382].
    * **Identification and Reconciliation API:** (Uses IRE for CMDB updates)[cite: 3958].
    * **Knowledge Management Articles API:** `/api/now/kb/articles`[cite: 4356].
    * **SCIM API:** `/api/now/scim/Users`, `/api/now/scim/Locations` (User/Group Provisioning)[cite: 4444, 4497].
* **Mobile SDK APIs (Examples):**
    * `NowChatConfiguration`: `closeButtonText()`, `closeButtonImage()`[cite: 4825, 4826].
    * `NowRecord`: Object for handling record data[cite: 2277].
* **Standard JavaScript:** `JSON`, `String`, `Array`, `RegExp` methods.

## Roles

* **Now Assist Analytics:** `sn_na_analytics.viewer`, `sn_na_analytics.admin`.
* **Predictive Intelligence:** `ml_admin`.
* **Document Intelligence:** `sn_docintel.admin`, `sn_docintel.viewer`, `sn_docintel.extraction_agent`, `sn_docintel.creation_agent`, `sn_docintel.manager`.
* **Now Assist Data Kit:** `sn_data_kit.admin`, `sn_data_kit.analyst`.
* **AI Assets API:** `asset`, `model_manager`[cite: 2379].

## System Properties

* **Natural Language Query (NLQ):** `com.snc.listv2.nlq.lists.append_query`[cite: 2798].
* **Agentic AI (Potential):** `sn_aia.ltm.*` (Relating to Long-Term Memory).

## Frameworks / Consoles / Concepts

* AI Agent Studio
* Now Assist Admin Console
* Now Assist Panel
* Generative AI Controller
* Now Assist Skill Kit
* Now Assist Data Kit
* AI Governance
* Flow Designer
* Natural Language Understanding (NLU)
* Natural Language Query (NLQ)
* Predictive Intelligence
* Document Intelligence
* Task Intelligence
* Retrieval-Augmented Generation (RAG)
* AI Search
* Group Action Framework (GAF)
* Dot-walking (in GlideRecord, REST API parameters) [cite: 38]
* Scoped vs. Global applications/APIs [cite: 5001, 5003]
* `@fluent-ignore` directive (for code management) [cite: 4663]